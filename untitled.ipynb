{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real time auto-refresh analysis\n",
    "\n",
    "Suppose we need to create a new backend application so an existing app can know when to refresh ceratin parts of its contents. Which method to use?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polling\n",
    "Polling involves the client making periodic requests to the server to check for new data. In the context of real-time auto refresh, the client would periodically poll the server to check for if some of the currently viewed content had any changes.\n",
    "\n",
    "Polling is easy to implement and works well for applications with a small number of clients. However, it can be inefficient for large-scale applications as it generates a lot of unnecessary network traffic. This can result in increased server load, increased latency, and higher costs due to increased bandwidth usage.\n",
    "\n",
    "### Long Polling:\n",
    "Long polling is a variation of polling where the server does not immediately respond to the client's request if there is no new data. Instead, the server waits until new data is available before responding. This reduces the number of unnecessary requests, as the client does not need to continually poll the server.\n",
    "\n",
    "So, for our app to handle the auto refresh with polling we would have to poll to our new backend asking if any of the content a user is currently viewing should be refreshed.\n",
    "\n",
    "To implement this approach we could propose the following architecture:\n",
    "\n",
    "![Alt text](Untitled%20Diagram.drawio.png)\n",
    "\n",
    "It consists of a new backend that has a redis cache where it saves all the content every user has accessed. It also assumes that the Legacy Content Backend has a way to trigger an event that updates our cache contents whenever a new change occurs. It could be an endpoint on the new backend being called through an internal VPC or it's own lambda upating directly the redis cache.\n",
    "\n",
    "Here, the client polls the new backend and sends the content that needs to be checked for auto-refreshing. The new backend checks its cache and see if the content requested had any changes. In case there's any, it sends back the updated data allowing the client app to rather update its client cache or refetch the outdated queries.\n",
    "\n",
    "\n",
    "To scale this approach in cases of high traffic we could load balance our backend with replicas like so:\n",
    "\n",
    "![Alt text](Untitled%20Diagram.drawio%20(1).png)\n",
    "\n",
    "This brings some disadvantages, as it would become tricky to use a replica's endpoint through a VPC to trigger the cache update.\n",
    "\n",
    "Also each replica would still have to do READ statements into redis, meaning we would have to implement some sharding into our redis storage to handle too many traffic.\n",
    "\n",
    "## WebSockets\n",
    "\n",
    "WebSockets provide a persistent, bi-directional communication channel between a client and a server. With WebSockets, the server can push data to the client at any time, and the client can also send data to the server whenever it needs to. This makes it an ideal solution for real-time communication between a client and a server.\n",
    "\n",
    "To address the auto-refresh problem using WebSockets, we could propose the following architecture:\n",
    "\n",
    "![Alt text](Untitled%20Diagram.drawio%20(2).png)\n",
    "\n",
    "This consists of something similar to the polling arch, with they key difference being the role that the redis cache has. Here it works an an Event log of all the events that were triggered by the Legacy Backend.\n",
    "\n",
    "Here, the client connects to any backend replica and sends an event informing the backend which content should be checked for auto-refreshing. The backend then adds this user connection to specific \"Rooms\" (as in a Chat room) according to what data he is listening to. Finally, each replica would be connected to Redis with the sub/pub method, so anytime a new entry is added into redis, each instance will receive such data and be able to trigger an event for all user that should be informed.\n",
    "\n",
    "This is a bit more complex to develop since we have to add a bunch of new dependencies to our frontend app and have to code a faithful reconnect logic in case the websocket connection fails but gives chance to think and develop a lot of new features that may be able to use the new bi-directional communication.\n",
    "\n",
    "The disadvantages of this is that it can be slow to auto-scale since whenever a new replica is created behind the load balancer, it'll take time for it to have new connections. There's also a concern for when a new backend release is deployed since, when that happens, all the currently connected clients will be forced out and an incorrect implementation of the reconnect feature might crowd our servers with incoming new connections.\n",
    "\n",
    "[Websockets vs Long Polling](https://ably.com/blog/websockets-vs-long-polling)\n",
    "\n",
    "[Websockets Performance](https://ably.com/topic/scaling-socketio#socket-io-performance-review)\n",
    "\n",
    "[WebSocket vs Long Polling](https://www.pubnub.com/blog/long-polling-vs-websockets/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
